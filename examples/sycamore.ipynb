{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_circuits import QuantumCircuit\n",
    "from artensor import (\n",
    "    AbstractTensorNetwork, \n",
    "    ContractionTree, \n",
    "    find_order, \n",
    "    contraction_scheme,\n",
    "    tensor_contraction,\n",
    "    contraction_scheme_sparse,\n",
    "    tensor_contraction_sparse\n",
    ")\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we load the sycamore quantum circuit with $n=30$, $m=14$ and EFGH sequence. `sc_target=30` means the largest size of intermediate tensors is $2^{30}$ (since the data type is `complex64`, it will take about 8G of memory). Thus, in order to perform such a contraction, you need a GPU with memory larger than 24G (`einsum` operator in pytorch need to take 3 times of involving tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, seq, device, sc_target, seed = 30, 14, 'EFGH', 'cuda', 30, 0\n",
    "qc = QuantumCircuit(n, m, seq=seq)\n",
    "edges = []\n",
    "for i in range(len(qc.neighbors)):\n",
    "    for j in qc.neighbors[i]:\n",
    "        if i < j:\n",
    "            edges.append((i, j))\n",
    "neighbors = list(qc.neighbors)\n",
    "final_qubits = set(range(len(neighbors) - n, len(neighbors)))\n",
    "tensor_bonds = {\n",
    "    i: [edges.index((min(i, j), max(i, j))) for j in neighbors[i]] \n",
    "    for i in range(len(neighbors)) if i not in final_qubits\n",
    "} # open tensor network without final state\n",
    "bond_dims = {i:2.0 for i in range(len(edges))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contract the open tensor network corresponding to the quantum circuit, to get the overall $2^{30}$ amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_slicing = [(0, 22), (1, 11), (24, 34), (0, 47), (2, 10), (3, 13), (1, 12), (23, 36), (0, 24), (2, 35), (1, 3), (0, 23), (60, 71), (59, 70), (50, 58), (2, 48), (0, 1), (60, 81), (59, 83), (50, 69), (28, 38), (0, 2), (59, 60), (17, 27), (41, 76), (28, 50), (0, 59), (5, 18), (17, 40), (26, 37), (29, 41), (0, 28), (5, 7), (17, 26), (0, 29), (5, 54), (0, 17), (52, 65), (64, 74), (9, 19), (0, 5), (52, 64), (9, 20), (8, 21), (4, 14), (6, 15), (0, 52), (75, 85), (32, 45), (8, 9), (46, 56), (4, 6), (0, 75), (32, 33), (55, 68), (31, 44), (30, 42), (8, 46), (25, 49), (4, 16), (0, 107), (57, 82), (43, 53), (32, 80), (55, 67), (30, 31), (8, 66), (4, 25), (0, 57), (88, 94), (61, 77), (32, 43), (55, 93), (8, 30), (62, 78), (0, 4), (39, 88), (32, 61), (8, 55), (51, 62), (0, 39), (8, 32), (73, 84), (51, 72), (0, 8), (96, 104), (63, 73), (0, 51), (63, 96), (95, 105), (79, 92), (0, 63), (95, 116), (97, 106), (0, 79), (95, 97), (117, 128), (118, 130), (86, 113), (91, 102), (0, 95), (117, 118), (86, 91), (0, 117), (0, 86), (90, 101), (89, 100), (103, 114), (0, 90), (87, 89), (140, 150), (103, 115), (0, 87), (103, 140), (98, 109), (126, 137), (0, 103), (98, 110), (139, 141), (126, 127), (99, 111), (0, 98), (126, 139), (0, 99), (112, 148), (131, 143), (135, 146), (0, 126), (112, 119), (120, 131), (122, 134), (123, 135), (0, 112), (120, 121), (122, 123), (0, 120), (133, 145), (136, 147), (0, 122), (108, 133), (124, 138), (125, 136), (0, 108), (132, 144), (124, 125), (0, 132), (129, 142), (124, 149), (0, 129), (0, 124)]\n",
      "slicing_bonds = {}\n"
     ]
    }
   ],
   "source": [
    "order_slicing, slicing_bonds, ctree_new = find_order(\n",
    "    tensor_bonds, bond_dims, seed, \n",
    "    sc_target=sc_target, trials=5, \n",
    "    iters=10, slicing_repeat=1, betas=np.linspace(3.0, 21.0, 61)\n",
    ")\n",
    "print('order_slicing =', order_slicing)\n",
    "print('slicing_bonds =', slicing_bonds)\n",
    "\n",
    "tensors = []\n",
    "for x in range(len(qc.tensors)):\n",
    "    if x not in final_qubits:\n",
    "        tensors.append(qc.tensors[x].to(device))\n",
    "\n",
    "scheme, bonds_final = contraction_scheme(ctree_new)\n",
    "\n",
    "final_qubits = sorted(final_qubits)\n",
    "permute_dims = [0] * len(final_qubits)\n",
    "for x in range(len(bonds_final)):\n",
    "    _, y = edges[bonds_final[x]]\n",
    "    permute_dims[list(final_qubits).index(y)] = x\n",
    "full_amps = tensor_contraction(\n",
    "    deepcopy(tensors), scheme\n",
    ").permute(permute_dims).reshape(-1).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of the relation between slicing edges and fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after slicing 1 edges, fidelity now is 0.49384 (estimated value 0.5)\n",
      "after slicing 2 edges, fidelity now is 0.26454 (estimated value 0.25)\n",
      "after slicing 3 edges, fidelity now is 0.13284 (estimated value 0.125)\n",
      "after slicing 4 edges, fidelity now is 0.06635 (estimated value 0.0625)\n",
      "after slicing 5 edges, fidelity now is 0.03350 (estimated value 0.03125)\n",
      "after slicing 6 edges, fidelity now is 0.01619 (estimated value 0.015625)\n",
      "after slicing 7 edges, fidelity now is 0.00608 (estimated value 0.0078125)\n",
      "after slicing 8 edges, fidelity now is 0.00304 (estimated value 0.00390625)\n"
     ]
    }
   ],
   "source": [
    "slicing_edges_manually_select = [\n",
    "    (44, 66), (46, 66), (69, 94), (81, 94), \n",
    "    (88, 99), (94, 116), (111, 127), (112, 122)\n",
    "]\n",
    "\n",
    "tensors_slicing = deepcopy(tensors)\n",
    "slicing_indices = {}\n",
    "neighbors_copy = deepcopy(neighbors)\n",
    "tensor_network = AbstractTensorNetwork(\n",
    "    deepcopy(tensor_bonds), \n",
    "    deepcopy(bond_dims))\n",
    "\n",
    "while len(slicing_edges_manually_select):\n",
    "    slicing_edge = slicing_edges_manually_select.pop(0)\n",
    "    x, y = slicing_edge\n",
    "    idx_x_y = neighbors_copy[x].index(y)\n",
    "    idx_y_x = neighbors_copy[y].index(x)\n",
    "    neighbors_copy[x].pop(idx_x_y)\n",
    "    neighbors_copy[y].pop(idx_y_x)\n",
    "    slicing_indices[(x, y)] = (idx_x_y, idx_y_x)\n",
    "    tensors_slicing[x] = tensors_slicing[x].select(idx_x_y, 0)\n",
    "    tensors_slicing[y] = tensors_slicing[y].select(idx_y_x, 0)\n",
    "\n",
    "    tensor_network.slicing(edges.index(slicing_edge))\n",
    "    ctree_appro = ContractionTree(deepcopy(tensor_network), order_slicing, 0)\n",
    "    scheme, _ = contraction_scheme(ctree_appro)\n",
    "    appro_amps = tensor_contraction(\n",
    "        deepcopy(tensors_slicing), scheme\n",
    "    ).permute(permute_dims).reshape(-1).cpu()\n",
    "    fidelity = (\n",
    "        (full_amps.conj() @ appro_amps.reshape(-1)).abs() /\n",
    "        (full_amps.abs().square().sum().sqrt() * appro_amps.abs().square().sum().sqrt())\n",
    "    ).square().item()\n",
    "    \n",
    "    print(\n",
    "        'after slicing {} edges, fidelity now is {:.5f} (estimated value {})'.format(\n",
    "            len(slicing_indices), fidelity, 1/2**(len(slicing_indices))\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the amplitudes calculated by Google using Schrodinger-Feynman algorithm as the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_samples(filename):\n",
    "    import os\n",
    "    if os.path.exists(filename):\n",
    "        samples_data = []\n",
    "        with open(filename, 'r') as f:\n",
    "            l = f.readlines()\n",
    "        f.close()\n",
    "        for line in l:\n",
    "            ll = line.split()\n",
    "            samples_data.append((ll[0], float(ll[1]) + 1j*float(ll[2])))\n",
    "        return samples_data\n",
    "    else:\n",
    "        raise ValueError(\"{} does not exist\".format(filename))\n",
    "\n",
    "data = read_samples('amplitudes_n30_m14_s0_e0_pEFGH_10000.txt')\n",
    "max_bitstrings = 1_000\n",
    "bitstrings = [data[i][0] for i in range(max_bitstrings)]\n",
    "amplitude_google = np.array([data[i][1] for i in range(max_bitstrings)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the result calculated by sparse-state is identical to Goggle's result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitstring amplitude correct ratio:0.995\n"
     ]
    }
   ],
   "source": [
    "tensors_sparsestate = []\n",
    "for i in range(len(qc.tensors)):\n",
    "    if i in final_qubits:\n",
    "        tensors_sparsestate.append(\n",
    "            torch.tensor([[1, 0], [0, 1]], dtype=torch.complex64, device=device)\n",
    "        )\n",
    "    else:\n",
    "        tensors_sparsestate.append(qc.tensors[i].to(device))\n",
    "\n",
    "tensor_bonds = {\n",
    "    i:[edges.index((min(i, j), max(i, j))) for j in neighbors[i]] \n",
    "    for i in range(len(neighbors))\n",
    "} # now all tensors will be included\n",
    "\n",
    "order_slicing, slicing_bonds, ctree_new = find_order(\n",
    "    tensor_bonds, bond_dims, final_qubits, seed, max_bitstrings, \n",
    "    sc_target=sc_target, trials=5, iters=10, slicing_repeat=1, \n",
    "    betas=np.linspace(3.0, 21.0, 61)\n",
    ")\n",
    "\n",
    "scheme_sparsestate, _, bitstrings_sorted = contraction_scheme_sparse(\n",
    "    ctree_new, bitstrings, sc_target=sc_target\n",
    ")\n",
    "\n",
    "slicing_edges = [edges[i] for i in slicing_bonds]\n",
    "slicing_indices = {}.fromkeys(slicing_edges)\n",
    "neighbors_copy = deepcopy(neighbors)\n",
    "for i, j in slicing_edges:\n",
    "    idxi_j = neighbors_copy[i].index(j)\n",
    "    idxj_i = neighbors_copy[j].index(i)\n",
    "    neighbors_copy[i].pop(idxi_j)\n",
    "    neighbors_copy[j].pop(idxj_i)\n",
    "    slicing_indices[(i, j)] = (idxi_j, idxj_i)\n",
    "\n",
    "\n",
    "amplitude_sparsestate = torch.zeros(\n",
    "    (len(bitstrings),), dtype=torch.complex64, device=device\n",
    ")\n",
    "for s in range(2**len(slicing_edges)):\n",
    "    configs = list(map(int, np.binary_repr(s, len(slicing_edges))))\n",
    "    sliced_tensors = tensors_sparsestate.copy()\n",
    "    for i in range(len(slicing_edges)):\n",
    "        m, n = slicing_edges[i]\n",
    "        idxm_n, idxn_m = slicing_indices[(m, n)]\n",
    "        sliced_tensors[m] = sliced_tensors[m].select(idxm_n, configs[i]).clone()\n",
    "        sliced_tensors[n] = sliced_tensors[n].select(idxn_m, configs[i]).clone()\n",
    "    amplitude_sparsestate += tensor_contraction_sparse(\n",
    "        sliced_tensors, scheme_sparsestate\n",
    "    )\n",
    "\n",
    "correct_num = 0\n",
    "for i in range(len(bitstrings_sorted)):\n",
    "    ind_google = bitstrings.index(bitstrings_sorted[i])\n",
    "    relative_error = abs(\n",
    "        amplitude_sparsestate[i].item() - amplitude_google[ind_google]\n",
    "    ) / abs(amplitude_google[ind_google])\n",
    "    if relative_error <= 0.05:\n",
    "        correct_num += 1\n",
    "print(f'bitstring amplitude correct ratio:{correct_num/max_bitstrings}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f95100793b43010e28ed80d490b665ccbe9af4299329cffb7252da6f38962fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
